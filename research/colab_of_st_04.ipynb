{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "deMbCjYA9UeX",
        "outputId": "4b6dd747-c9ba-4617-e243-4f7bc1bc03d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tvv7gE6GwXs-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.chdir(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = \"/content/drive/MyDrive/Deeplearning/CNNmodel\"\n",
        "os.chdir(ROOT)"
      ],
      "metadata": {
        "id": "s_OQR0JS-R5Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"Deep_CNN_classifier\")"
      ],
      "metadata": {
        "id": "16MepW7p-m2h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "e5qsOGpA8fp8",
        "outputId": "28458c70-3fce-4fcd-f352-809fa36f83bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artifacts  init_setup.sh  pyproject.toml\tsetup.cfg    tox.ini\n",
            "configs    LICENSE\t  README.md\t\tsetup.py\n",
            "docs\t   logs\t\t  requirements_dev.txt\tsrc\n",
            "dvc.lock   new_file.json  requirements.txt\ttemplate.py\n",
            "dvc.yaml   params.yaml\t  research\t\ttests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1dxqz32dwXtF"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TrainingConfig:\n",
        "    root_dir: Path\n",
        "    trained_model_path: Path\n",
        "    updated_base_model_path: Path\n",
        "    training_data: Path\n",
        "    params_epochs: int\n",
        "    params_batch_size: int\n",
        "    params_is_augmentation: bool\n",
        "    params_image_size: list\n",
        "    \n",
        "    \n",
        "@dataclass(frozen=True)\n",
        "class PrepareCallbacksConfig:\n",
        "    root_dir: Path\n",
        "    tensorboard_root_log_dir: Path\n",
        "    checkpoint_model_filepath: Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "\n",
        "logging_str = \"[%(asctime)s: %(levelname)s: %(module)s]: %(message)s\"\n",
        "log_dir = \"logs\"\n",
        "log_filepath = os.path.join(log_dir, \"running_logs.log\")\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, \n",
        "    format=logging_str,\n",
        "    handlers=[\n",
        "        logging.FileHandler(log_filepath),\n",
        "        logging.StreamHandler(sys.stdout),\n",
        "    ])\n",
        "\n",
        "logger = logging.getLogger(\"deepClassifierLogger\")"
      ],
      "metadata": {
        "id": "x4UVPXwrxn-q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-box\n",
        "!pip install ensure==1.0.2"
      ],
      "metadata": {
        "id": "9cZPIAQu6rnF",
        "outputId": "7a88f16b-f5be-41cc-bba1-11581228249d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-box\n",
            "  Downloading python_box-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: python-box\n",
            "Successfully installed python-box-6.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ensure==1.0.2\n",
            "  Downloading ensure-1.0.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from ensure==1.0.2) (1.15.0)\n",
            "Installing collected packages: ensure\n",
            "Successfully installed ensure-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from box.exceptions import BoxValueError\n",
        "from ensure import ensure_annotations\n",
        "from box import ConfigBox\n",
        "import yaml\n",
        "\n",
        "\n",
        "\n",
        "@ensure_annotations                      # IT MAKES SURE THAT CORRECT FORM OF VALUE IS PASSED AS ARGUMENTS to ensure certain type of returns\n",
        "def read_yaml(path_to_yaml: Path) -> ConfigBox:   #access values in dictionary like attributes\n",
        "    \"\"\"reads yaml file and returns\n",
        "\n",
        "    Args:\n",
        "        path_to_yaml (str): path like input\n",
        "\n",
        "    Raises:\n",
        "        ValueError: if yaml file is empty\n",
        "        e: empty file\n",
        "\n",
        "    Returns:\n",
        "        ConfigBox: ConfigBox type\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(path_to_yaml) as yaml_file:\n",
        "            content = yaml.safe_load(yaml_file)\n",
        "            logger.info(f\"yaml file: {path_to_yaml} loaded successfully\")\n",
        "            return ConfigBox(content)\n",
        "    except BoxValueError:\n",
        "        raise ValueError(\"yaml file is empty\")\n",
        "    except Exception as e:\n",
        "        raise e\n",
        "\n",
        "\n",
        "@ensure_annotations\n",
        "def create_directories(path_to_directories: list, verbose=True):\n",
        "    \"\"\"create list of directories\n",
        "\n",
        "    Args:\n",
        "        path_to_directories (list): list of path of directories\n",
        "        ignore_log (bool, optional): ignore if multiple dirs is to be created. Defaults to False.\n",
        "    \"\"\"\n",
        "    for path in path_to_directories:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        if verbose:\n",
        "            logger.info(f\"created directory at: {path}\")"
      ],
      "metadata": {
        "id": "DH6KRtA-w7L0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aeQuIB6mwXtI"
      },
      "outputs": [],
      "source": [
        "CONFIG_FILE_PATH = Path(\"/content/drive/MyDrive/Deeplearning/CNNmodel/Deep_CNN_classifier/configs/config.yaml\")\n",
        "PARAMS_FILE_PATH = Path(\"/content/drive/MyDrive/Deeplearning/CNNmodel/Deep_CNN_classifier/params.yaml\")\n",
        "#from deepClassifier.utils import read_yaml, create_directories\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4Njx8zHuwXtJ"
      },
      "outputs": [],
      "source": [
        "class ConfigurationManager:\n",
        "    def __init__(\n",
        "        self, \n",
        "        config_filepath = CONFIG_FILE_PATH,\n",
        "        params_filepath = PARAMS_FILE_PATH):\n",
        "        self.config = read_yaml(config_filepath)\n",
        "        self.params = read_yaml(params_filepath)\n",
        "        create_directories([self.config.artifacts_root])\n",
        "\n",
        "    \n",
        "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
        "        config = self.config.prepare_callbacks\n",
        "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
        "        create_directories([\n",
        "            Path(model_ckpt_dir),\n",
        "            Path(config.tensorboard_root_log_dir)\n",
        "        ])\n",
        "\n",
        "        prepare_callback_config = PrepareCallbacksConfig(\n",
        "            root_dir=Path(config.root_dir),\n",
        "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n",
        "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n",
        "        )\n",
        "\n",
        "        return prepare_callback_config\n",
        "    \n",
        "    \n",
        "    def get_training_config(self) -> TrainingConfig:\n",
        "        training = self.config.training\n",
        "        prepare_base_model = self.config.prepare_base_model\n",
        "        params = self.params\n",
        "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"PetImages\")\n",
        "        create_directories([\n",
        "            Path(training.root_dir)\n",
        "        ])\n",
        "\n",
        "        training_config = TrainingConfig(\n",
        "            root_dir=Path(training.root_dir),\n",
        "            trained_model_path=Path(training.trained_model_path),\n",
        "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
        "            training_data=Path(training_data),\n",
        "            params_epochs=params.EPOCHS,\n",
        "            params_batch_size=params.BATCH_SIZE,\n",
        "            params_is_augmentation=params.AUGMENTATION,\n",
        "            params_image_size=params.IMAGE_SIZE\n",
        "        )\n",
        "\n",
        "        return training_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1u-cWgWGwXtL"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "class PrepareCallback:\n",
        "    def __init__(self, config: PrepareCallbacksConfig):\n",
        "        self.config = config\n",
        "\n",
        "    @property\n",
        "    def _create_tb_callbacks(self):\n",
        "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "        tb_running_log_dir = os.path.join(\n",
        "            self.config.tensorboard_root_log_dir,\n",
        "            f\"tb_logs_at_{timestamp}\",\n",
        "        )\n",
        "        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n",
        "\n",
        "    @property\n",
        "    def _create_ckpt_callbacks(self):\n",
        "        return tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=self.config.checkpoint_model_filepath,\n",
        "            save_best_only=True\n",
        "        )\n",
        "\n",
        "    def get_tb_ckpt_callbacks(self):\n",
        "        return [\n",
        "            self._create_tb_callbacks,\n",
        "            self._create_ckpt_callbacks\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2UQujOTHwXtM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request as request\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "class Training:\n",
        "    def __init__(self, config: TrainingConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def get_base_model(self):\n",
        "        self.model = tf.keras.models.load_model(\n",
        "            self.config.updated_base_model_path\n",
        "        )\n",
        "\n",
        "    def train_valid_generator(self):\n",
        "\n",
        "        datagenerator_kwargs = dict(\n",
        "            rescale = 1./255,\n",
        "            validation_split=0.20\n",
        "        )\n",
        "\n",
        "        dataflow_kwargs = dict(\n",
        "            target_size=self.config.params_image_size[:-1],\n",
        "            batch_size=self.config.params_batch_size,\n",
        "            interpolation=\"bilinear\"\n",
        "        )\n",
        "\n",
        "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "            **datagenerator_kwargs\n",
        "        )\n",
        "\n",
        "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
        "            directory=self.config.training_data,\n",
        "            subset=\"validation\",\n",
        "            shuffle=False,\n",
        "            **dataflow_kwargs\n",
        "        )\n",
        "\n",
        "        if self.config.params_is_augmentation:\n",
        "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                rotation_range=40,\n",
        "                horizontal_flip=True,\n",
        "                width_shift_range=0.2,\n",
        "                height_shift_range=0.2,\n",
        "                shear_range=0.2,\n",
        "                zoom_range=0.2,\n",
        "                **datagenerator_kwargs\n",
        "            )\n",
        "        else:\n",
        "            train_datagenerator = valid_datagenerator\n",
        "\n",
        "        self.train_generator = train_datagenerator.flow_from_directory(\n",
        "            directory=self.config.training_data,\n",
        "            subset=\"training\",\n",
        "            shuffle=True,\n",
        "            **dataflow_kwargs\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def save_model(path: Path, model: tf.keras.Model):\n",
        "        model.save(path)\n",
        "\n",
        "\n",
        "    def train(self, callback_list: list):\n",
        "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
        "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
        "\n",
        "        self.model.fit(\n",
        "            self.train_generator,\n",
        "            epochs=self.config.params_epochs,\n",
        "            steps_per_epoch=self.steps_per_epoch,\n",
        "            validation_steps=self.validation_steps,\n",
        "            validation_data=self.valid_generator,\n",
        "            callbacks=callback_list\n",
        "        )\n",
        "\n",
        "        self.save_model(\n",
        "            path=self.config.trained_model_path,\n",
        "            model=self.model\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "r3VnCo8gwXtO",
        "outputId": "cc94e15a-175d-4e15-a26c-6165bf5099d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "50NZpp62wXtQ",
        "outputId": "585fc970-f4f9-4a3e-a180-a4ae9892f623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4998 images belonging to 2 classes.\n",
            "Found 20000 images belonging to 2 classes.\n",
            " 578/1250 [============>.................] - ETA: 28:30 - loss: 8.6309 - accuracy: 0.6274"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 [==============================] - 3697s 3s/step - loss: 6.1450 - accuracy: 0.6917 - val_loss: 0.9742 - val_accuracy: 0.8976\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    config = ConfigurationManager()\n",
        "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
        "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
        "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
        "    \n",
        "    training_config = config.get_training_config()\n",
        "    training = Training(config=training_config)\n",
        "    training.get_base_model()\n",
        "    training.train_valid_generator()\n",
        "    training.train(\n",
        "        callback_list=callback_list\n",
        "    )\n",
        "    \n",
        "except Exception as e:\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HraMkdJXwXtS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 (conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "79e4317a27277e9db2a8031ee067bd1fd66b84da12882355e6450b3700b854ac"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}